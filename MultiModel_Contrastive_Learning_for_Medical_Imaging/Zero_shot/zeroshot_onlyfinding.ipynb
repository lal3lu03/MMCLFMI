{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "src_path = os.path.split(os.getcwd())[0]\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "import json\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize, RandomResizedCrop, InterpolationMode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import clip_.clip as clip\n",
    "from clip_.clip import _transform\n",
    "from clip_.model import CLIPGeneral\n",
    "\n",
    "import training.zeroshot_data_crx as zeroshot_data\n",
    "import shutil\n",
    "\n",
    "# Set the GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 4\n",
      "Device IDs: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "device_count = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", device_count)\n",
    "device_ids = list(range(device_count))\n",
    "print(\"Device IDs:\", device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths = [\n",
    "    '/system/user/publicdata/CLOOB/paper/checkpoints_icml22/yfcc/clip_rn50_yfcc_epoch_28.pt',\n",
    "    '/system/user/publicdata/CLOOB/paper/checkpoints_icml22/yfcc/clip_rn50x4_yfcc_epoch_28.pt',\n",
    "    '/system/user/publicdata/CLOOB/paper/checkpoints_icml22/yfcc/clip_rn101_yfcc_epoch_28.pt',\n",
    "    '/system/user/publicdata/CLOOB/paper/checkpoints_icml22/yfcc/cloob_rn50_yfcc_epoch_28.pt',\n",
    "    '/system/user/publicdata/CLOOB/paper/checkpoints_icml22/yfcc/cloob_rn50x4_yfcc_epoch_28.pt',\n",
    "    '/system/user/publicdata/CLOOB/paper/checkpoints_icml22/yfcc/cloob_rn101_yfcc_epoch_28.pt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model_config_file = os.path.join('/system/user/hagenede/MIMIC_CXR_bachelor/Cloob_zero/cloob/src/training/model_configs', checkpoint['model_config_file'])\n",
    "\n",
    "    print(\"Device is\", device)\n",
    "\n",
    "    # Load model config\n",
    "    assert os.path.exists(model_config_file)\n",
    "    with open(model_config_file, 'r') as f:\n",
    "        model_info = json.load(f)\n",
    "    model = CLIPGeneral(**model_info)\n",
    "    preprocess = _transform(model.visual.input_resolution, is_train=False)\n",
    "\n",
    "    # Load model state dictionary\n",
    "    sd = checkpoint[\"state_dict\"]\n",
    "    sd = {k[len('module.'):]: v for k, v in sd.items()}  # Remove 'module.' prefix from keys for DataParallel\n",
    "    if 'logit_scale_hopfield' in sd:\n",
    "        sd.pop('logit_scale_hopfield', None)\n",
    "    model.load_state_dict(sd)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model, device_ids=device_ids)\n",
    "        print(\"Device IDs:\", device_ids)\n",
    "        print('model')\n",
    "        #next(model.parameters()).device print\n",
    "        print(model)\n",
    "        print('model.parameters().device')\n",
    "        print(next(model.parameters()).device)\n",
    "        print('model.module.visual.conv1.parameters().device')\n",
    "        print(next(model.module.visual.conv1.parameters()).device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model, preprocess, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model_config_file = os.path.join('/system/user/hagenede/MIMIC_CXR_bachelor/Cloob_zero/cloob/src/training/model_configs', checkpoint['model_config_file'])\n",
    "\n",
    "    print(\"Device is\", device)\n",
    "\n",
    "    # Load model config\n",
    "    assert os.path.exists(model_config_file)\n",
    "    with open(model_config_file, 'r') as f:\n",
    "        model_info = json.load(f)\n",
    "    model = CLIPGeneral(**model_info)\n",
    "    preprocess = _transform(model.visual.input_resolution, is_train=False)\n",
    "\n",
    "    # Load model state dictionary\n",
    "    sd = checkpoint[\"state_dict\"]\n",
    "    sd = {k[len('module.'):]: v for k, v in sd.items()}  # Remove 'module.' prefix from keys for DataParallel\n",
    "    if 'logit_scale_hopfield' in sd:\n",
    "        sd.pop('logit_scale_hopfield', None)\n",
    "    model.load_state_dict(sd)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        print(\"Device IDs:\", list(range(torch.cuda.device_count())))\n",
    "    else:\n",
    "        model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model, preprocess, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "Using 4 GPUs!\n",
      "Device IDs: [0, 1, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DataParallel(\n",
       "   (module): CLIPGeneral(\n",
       "     (visual): ModifiedResNet(\n",
       "       (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (layer1): Sequential(\n",
       "         (0): Bottleneck(\n",
       "           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (downsample): Sequential(\n",
       "             (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (1): Bottleneck(\n",
       "           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "         (2): Bottleneck(\n",
       "           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "       )\n",
       "       (layer2): Sequential(\n",
       "         (0): Bottleneck(\n",
       "           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (downsample): Sequential(\n",
       "             (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (1): Bottleneck(\n",
       "           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "         (2): Bottleneck(\n",
       "           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "         (3): Bottleneck(\n",
       "           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "       )\n",
       "       (layer3): Sequential(\n",
       "         (0): Bottleneck(\n",
       "           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (downsample): Sequential(\n",
       "             (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (1): Bottleneck(\n",
       "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "         (2): Bottleneck(\n",
       "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "         (3): Bottleneck(\n",
       "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "         (4): Bottleneck(\n",
       "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "         (5): Bottleneck(\n",
       "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "       )\n",
       "       (layer4): Sequential(\n",
       "         (0): Bottleneck(\n",
       "           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (downsample): Sequential(\n",
       "             (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (1): Bottleneck(\n",
       "           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "         (2): Bottleneck(\n",
       "           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (avgpool): Identity()\n",
       "           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "         )\n",
       "       )\n",
       "       (attnpool): AttentionPool2d(\n",
       "         (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "         (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "         (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "         (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "       )\n",
       "     )\n",
       "     (transformer): TextTransformer(\n",
       "       (transformer): Transformer(\n",
       "         (resblocks): Sequential(\n",
       "           (0): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (1): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (2): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (3): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (4): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (5): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (6): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (7): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (8): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (9): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (10): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (11): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (token_embedding): Embedding(49408, 512)\n",
       "       (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Compose(\n",
       "     Resize(size=224, interpolation=bicubic, max_size=None, antialias=warn)\n",
       "     CenterCrop(size=(224, 224))\n",
       "     <function _convert_to_rgb at 0x7f480d506dc0>\n",
       "     ToTensor()\n",
       "     Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       " ),\n",
       " device(type='cuda'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_checkpoint(checkpoint_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_classifier(model, classnames, templates, device):\n",
    "    with torch.no_grad():\n",
    "        zeroshot_weights = []\n",
    "        tokenizer = clip.tokenize  # Move tokenizer definition outside the loop\n",
    "        for classname in tqdm(classnames):\n",
    "            texts = [template(classname) for template in templates]  # format with class\n",
    "            texts = tokenizer(texts).to(device)  # tokenize and move to CUDA device\n",
    "            class_embeddings = model.module.encode_text(texts)  # Access the encode_text method from model.module\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            class_embedding = class_embeddings.mean(dim=0)\n",
    "            class_embedding /= class_embedding.norm()\n",
    "            zeroshot_weights.append(class_embedding)\n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).to(device)\n",
    "    return zeroshot_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, classifier, dataloader, device, accuracy_metric):\n",
    "    with torch.no_grad():\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "        for images, target in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # predict\n",
    "            image_features = model.module.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            logits = image_features @ classifier\n",
    "\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_targets.append(target.cpu())\n",
    "\n",
    "        all_logits = torch.cat(all_logits).numpy()\n",
    "        all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "        acc = accuracy_metric(all_targets, all_logits.argmax(axis=1)) * 100.0\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = zeroshot_data.classes_CRX_one\n",
    "prompt_templates = zeroshot_data.illness_templates_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        image_path = row['jpg_path']\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = row['Finding']\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jpg = pd.read_csv('/system/user/publicdata/MIMIC_CXR/hageneder/jpg_path_fingings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>jpg_path</th>\n",
       "      <th>Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50414267</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50414267</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53189527</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53189527</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53911762</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377090</th>\n",
       "      <td>57132437</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377091</th>\n",
       "      <td>57132437</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377092</th>\n",
       "      <td>55368167</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377093</th>\n",
       "      <td>58621812</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377094</th>\n",
       "      <td>58971208</td>\n",
       "      <td>/system/user/publicdata/MIMIC_CXR/hageneder/JP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377095 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id                                           jpg_path  Finding\n",
       "0       50414267  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        0\n",
       "1       50414267  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        0\n",
       "2       53189527  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        0\n",
       "3       53189527  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        0\n",
       "4       53911762  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        0\n",
       "...          ...                                                ...      ...\n",
       "377090  57132437  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        0\n",
       "377091  57132437  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        0\n",
       "377092  55368167  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        1\n",
       "377093  58621812  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        1\n",
       "377094  58971208  /system/user/publicdata/MIMIC_CXR/hageneder/JP...        1\n",
       "\n",
       "[377095 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: /system/user/publicdata/CLOOB/paper/checkpoints_icml22/yfcc/clip_rn50_yfcc_epoch_28.pt\n",
      "Device is cuda\n",
      "Using 4 GPUs!\n",
      "Device IDs: [0, 1, 2, 3]\n",
      "Calculating the text embeddings for all classes of the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the image embeddings for all images of the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1474 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "df_accuracy = pd.DataFrame(columns=['model', 'accuracy'])\n",
    "\n",
    "for checkpoint_path in checkpoint_paths:\n",
    "    print(\"Loading checkpoint:\", checkpoint_path)\n",
    "    model, preprocess, device = load_checkpoint(checkpoint_path)\n",
    "\n",
    "    #data_path = '/system/user/publicdata/MIMIC_CXR/hageneder/embeddings/embedding_0_1'\n",
    "    dataset = CustomImageDataset(df_test, transform=preprocess)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=256, num_workers=4)\n",
    "\n",
    "    model.eval()\n",
    "    accuracy_metric = accuracy_score\n",
    "\n",
    "    print(\"Calculating the text embeddings for all classes of the dataset\", flush=True)\n",
    "    classifier = zero_shot_classifier(model, classnames, prompt_templates, device)\n",
    "\n",
    "    print(\"Calculating the image embeddings for all images of the dataset\", flush=True)\n",
    "    accuracy = run(model, classifier, dataloader, device, accuracy_score)\n",
    "    print('Zeroshot accuracy:', accuracy.round(2))\n",
    "    #add the accuracy in a pandas dataframe and a column for the checkpoint path but only the last part of the path (after the last /)\n",
    "    new_row = {'model': checkpoint_path.split('/')[-1], 'accuracy': round(accuracy, 2)}\n",
    "    df_accuracy = pd.concat([df_accuracy, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
